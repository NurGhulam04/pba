---

# ğŸ“Š Sentiment Analysis â€“ Okejek App Reviews

Repositori ini berisi proyek **Analisis Sentimen** terhadap ulasan pengguna aplikasi **Okejek** yang diambil dari **Google Play Store**.
Proyek ini dibuat sebagai bagian dari tugas analisis teks menggunakan teknik **Natural Language Processing (NLP)**.

---

## ğŸ“‚ Struktur Proyek

```
.
â”œâ”€â”€ dataset
â”‚   â”œâ”€â”€ dirty_okejek_review.csv     # Dataset mentah hasil scraping
â”‚   â””â”€â”€ cleaned_okejek_review.csv   # Dataset setelah preprocessing
â”‚
â”œâ”€â”€ notebook
â”‚   â”œâ”€â”€ Scrapping_and_lowercasing.ipynb   # Scraping + pembersihan awal
â”‚   â”œâ”€â”€ Tokenization.ipynb                # Tokenisasi teks
â”‚   â”œâ”€â”€ Stemmer.ipynb                     # Stemming kata
â”‚   â”œâ”€â”€ TFIDF.ipynb                       # Representasi TF-IDF
â”‚   â”œâ”€â”€ BoW.ipynb                         # Representasi Bag-of-Words
â”‚   â”œâ”€â”€ Finding_common_words.ipynb        # Analisis kata yang sering muncul
â”‚   â”œâ”€â”€ WordCloud.ipynb                   # Visualisasi Word Cloud
â”‚   â”œâ”€â”€ EDA.ipynb                         # Exploratory Data Analysis
â”‚   â””â”€â”€ Sentiment_Analysis.ipynb          # Notebook utama (klasifikasi sentimen)
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ Teknologi yang Digunakan

* **Python** (Jupyter Notebook)
* **Library NLP & ML**:

  * `pandas`, `numpy` â†’ manipulasi data
  * `scikit-learn` â†’ machine learning (TF-IDF, klasifikasi)
  * `nltk` / `Sastrawi` â†’ preprocessing teks (stopwords, stemming)
  * `matplotlib`, `seaborn`, `wordcloud` â†’ visualisasi

---

## ğŸš€ Langkah Menjalankan Proyek

1. **Clone repositori**

   ```bash
   git clone https://github.com/NurGhulam04/pba.git
   cd pba
   ```

2. **Buat environment baru (opsional)**

   ```bash
   python -m venv venv
   source venv/bin/activate   # Linux/Mac
   venv\Scripts\activate      # Windows
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

   > Jika `requirements.txt` belum ada, jalankan `pip freeze > requirements.txt` setelah semua library terpasang.

4. **Jalankan Jupyter Notebook**

   ```bash
   jupyter notebook
   ```

   Buka file pada folder `notebook/`, misalnya `Sentiment_Analysis.ipynb`.

---

## ğŸ“Š Alur Analisis

1. **Scraping Data** â†’ Mengambil review dari Google Play Store.
2. **Preprocessing** â†’ Lowercasing, cleaning, tokenisasi, stemming, stopword removal.
3. **Representasi Teks**:

   * Bag-of-Words (BoW)
   * Term Frequency - Inverse Document Frequency (TF-IDF)
4. **EDA & Visualisasi** â†’ WordCloud, distribusi kata, analisis kata umum.
5. **Modeling** â†’ Klasifikasi sentimen positif/negatif menggunakan algoritma ML.
6. **Evaluasi** â†’ Mengukur performa model dengan metrik (accuracy, precision, recall, f1-score).

---

## ğŸ“Œ Hasil & Temuan

* Dataset berhasil dibersihkan dari noise seperti emoji, angka, tanda baca, dan stopwords.
* WordCloud dan analisis kata membantu memahami kata dominan yang muncul.
* Model berbasis **TF-IDF + klasifikasi** memberikan performa yang lebih baik dibandingkan representasi BoW.

---

## âœï¸ Kontributor

* [NurGhulam04](https://github.com/NurGhulam04)

---

Mau aku bikinin juga file **`requirements.txt`** biar gampang install dependensinya, atau cukup README aja?
